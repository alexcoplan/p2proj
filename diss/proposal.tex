% TODO: VERSION CONTROL IS NOT BACKUP!

% Note: this file can be compiled on its own, but is also included by
% diss.tex (using the docmute.sty package to ignore the preamble)
\documentclass[12pt,a4paper,twoside]{article}
\usepackage[UKenglish]{isodate}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage[margin=25mm]{geometry}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{enumitem}
% \usepackage{mathpazo}
% \usepackage{eulervm}
\usepackage{microtype}
\usepackage{longtable} % so we can break the timetable across two pages

\usepackage[style=numeric,backend=bibtex]{biblatex}
\bibliography{refs.bib}

\begin{document}

\cleanlookdateon

\begin{center}
\Large
Computer Science Tripos -- Part II -- Project Proposal\\[4mm]
\LARGE
A Comparison of Statistical Models and Recurrent Neural Networks Applied to the
Generation of Music\\[4mm]

\large
Alex Coplan, St Catharine's College

Originator: Alex Coplan

\today
\end{center}

\vspace{5mm}

\textbf{Project Supervisor:} Matthew Ireland

\textbf{Director of Studies:} Dr S. Taraskin

\textbf{Project Overseers:} Dr M. Fiore \& Dr I. Leslie

% Main document

\section*{Introduction}

The goal of this project is to implement, evaluate, and compare two different
techniques for the algorithmic generation of music. I am particularly interested
in the generation of melody, and ultimately, \emph{polyphony}: multiple
independent melodies interacting with each other in harmonic coherence. In
particular, the two classes of techniques I intend to consider for this project
are:
\begin{itemize}[itemsep=0mm]
	\item Statistical history models such as \emph{multiple viewpoint
			systems} \cite{conklin1995viewpoints}.
	\item Recurrent neural networks.
\end{itemize}

The exact statistical model(s) to be investigated will be determined by the end
of the research phase of the project.

Algorithmic composition is of general interest in computational creativity, but
also has a number of practical applications; one such application being in
\emph{machine-assisted composition}, where a music generation tool aids a human
composer by extending or generating musical ideas. Such tools would be used by a
wide variety of music practitioners.

My intention is to undertake an investigation into the algorithmic composition
of polyphonic music. The first major problem that needs to be tackled in such an
endeavour is that of melody generation. Once this problem has been addressed,
one would subsequently consider the problem ``given a melody (the
\emph{subject}), compose a second (independent) melody (the
\emph{countersubject}) which interacts with, and is coherent with the subject.''
Since the lines in polyphony should be \emph{independent} melodies, it is
necessary to approach the problem of melody generation first.

I therefore propose that the core of the project investigate the application of
these techniques to melody generation. As an optional extension, an
investigation could then be carried out into the composition of two-part
polyphonic music, using these techniques and/or extensions thereof.

I shall follow the approach often taken in the literature of restricting the
domain of source material to stem from a particular musical idiom, e.g.\
\cite{pearce2001evaluation}. This is desirable for a number of reasons, not
least because it introduces a useful evaluation criterion: do the compositions
produced by the system exhibit a coherent musical style, consistent with that
exhibited by the material in the corpus?

In order for this project to be evaluated effectively, in addition to any
information-theoretic or music-theoretic analyses, it is necessary to perform
listening trials on human subjects. Pearce et al.\ \cite{pearce2001evaluation}
outline a framework for evaluation which allows more scientific claims to be
made as a result of the evaluation process. Evaluation would be performed in the
form of a blind trial where the subjects are asked to classify compositions as
human or machine-composed. In this work, it is noted that the participants
exhibited a bias towards classifying compositions as machine composed. This is
something that should be taken into account when designing the evaluation
methodology. An avenue for investigation in this respect is the method of
\emph{three-alternative forced choice}.

Conklin \cite{conklin2003music} notes that random walk is not necessarily the
best method of sampling from a statistical distribution such as that of a
multiple viewpoint system or Markov chain. In this project, I would therefore
also consider exploring different techniques for sampling from statistical
models.
 
\subsection*{Background}

Markov processes are natural statistical models for the analysis of melody, and
are well known as tools for composition \cite{ames1989markov}. Although
effective, Markov processes are far from perfect tools for modelling music.
Specifically, a basic pitch-duration Markov process disregards a considerable
amount of musical information available in the context
\cite{conklin1995viewpoints}.  

However, simply incorporating more musical features into the state space of a
Markov chain leads to an exponential blow-up in space complexity and
necessitates both a large amount of training data for good performance, as well
as solving the sparse data problem (\cite{conklin2003music}, section 2.1).
Moreover, Markov chains do not make use of the long-term context of a system,
which is necessary for modelling the broader sense of sequence and structure
which is present in music.

Conklin et al.\ \cite{conklin1995viewpoints} introduce the method of
\emph{multiple viewpoints} which uses the interpolation of the predictions of
many different context models, each of which considers a different musical
attribute (or some combination of attributes). These include both short-term and
long-term attributes, enabling this method to capture sequence and structure.

It is well known that Recurrent Neural Networks (RNNs) can effectively generate
sequences. RNNs have seen more successful application in music following the
introduction of long short-term memory (LSTM) techniques \cite{eck2002lstm}.
Without use of LSTM, RNNs exhibit similar problems to Markov chains in that the
output does not contain the elements of sequence and structure that one might
expect from compositions in the corpus.

\section*{Starting point}

In Lent term of 2016, I gave a talk (as part of Churchill college's Computer
Science talk series) on melody generation using Markov chains. I also
constructed a demo in Ruby which implemented a parser for ABC
notation\footnote{\url{http://abcnotation.com/}} along with a simple Markov
chain model, trained of a small corpus of hymn tunes, which generated tunes by
random walk. 

Although this experience led me to this choice of project, the implementation of
a model such as a multiple viewpoint system is considerably more involved, and
the architecture vastly different. The implementation of this model will
therefore be carried out from scratch.  The neural network will be implemented
using a library such as Google's
TensorFlow\footnote{\url{https://www.tensorflow.org/}}.

As an organ scholar (and previously an A-Level music student), I have
considerable experience with performing polyphonic music (and some experience of
analysis), especially that of the renaissance and baroque eras. I believe this
domain knowledge will prove especially useful for making musically-informed
decisions in this project. 

\section*{Resources required}

For this project I shall primarily use my own laptop. Git will be used for
version control, with the repository stored on GitHub. I will perform backups of
the project files to an external hard drive as well as multiple cloud providers
(Google, Apple, Dropbox) and the MCS. Should my main computer suddenly fail, I
can easily continue the project using MCS computers by cloning the code from the
GitHub repository.

Although datasets can easily be compiled from online sources, it may also be of
use to have a MIDI keyboard to be able to input arbitrary musical data. I own a
MIDI keyboard which would be suitable for these purposes. I will make use of
open-source software (such as MuseScore\footnote{\url{https://musescore.org/}})
for synthesis of MIDI and other musical data. I require no other special
resources.

\section*{Work to be done}

I will employ an agile software development methodology when undertaking this
project. The ordered list of sub-tasks within this project are:
\begin{enumerate}

\item Devising and implementing an internal representation of musical data,
	along with a simple ``music theory engine'' to process this data.  

\item Implementing a simple parser for some form of input notation (ABC, MIDI,
	MusicXML); the exact form to be determined in the research phase.  

\item Implementing and iteratively refining the statistical model (e.g. multiple
	viewpoint system).

\item Implementing and iteratively refining the RNN for melody generation.  

\item Designing and carrying out a scheme for human evaluation.

\item Making iterative improvements to the two models.

\end{enumerate}

\section*{Success criteria}

\subsection*{Core Tasks}

The project will be a success if I have:
\begin{itemize}
	\item Successfully implemented a statistical model such as a multiple
		viewpoint system capable of generating melody.
	\item Successfully implemented a technique based on recurrent neural
		networks capable of generating melody.
	\item Performed an evaluation and comparison of the two
		models, answering questions such as:
	\begin{itemize}
		\item Can human subjects distinguish the machine-composed output
			from the human-composed samples in the corpus?
		\item Do human subjects classify the machine-composed output as
			adhering to the specified style?
	\end{itemize}

	Note that the success of the evaluation stage is not predicated on the
	answers to the questions given above, but merely whether the evaluation
	is conducted in a scientific manner.
\end{itemize}

\subsection*{Extension Tasks}

The project will be judged as a success if all the core tasks have been
completed. The extension tasks won't be used to judge the success of the
project, but it will have gone above and beyond expectations if one of them is
completed.

These possible extensions include:
\begin{itemize}
	\item Extending a multiple viewpoint system to generate polyphony.
	\item Extending a RNN to generate polyphony.
	\item Exploring extensions and adaptations of multiple viewpoint
		systems.
\end{itemize}

\newpage

\section*{Timetable}

\begin{longtable}{ p{4cm} | p{11cm} } \hline 

06/10/16 - 19/10/16 Michaelmas Weeks 1-2 & \textbf{Proposal}. Done. \\ \hline
20/10/16 - 02/11/16 Michaelmas Weeks 3-4 & \textbf{Research Phase}. 
Research multiple viewpoint systems, RNNs, and evaluation techniques.
Investigate options for corpus material and format. Devise and fix an internal
representation for musical data. Design specific multiple viewpoint system based
on \cite{whorley2013phd}. The corpus should also be prepared as fully as
possible during this stage. Familiarisation with libraries (e.g. TensorFlow)
should be accomplished during this phase.

\textbf{Deliverable}: Report summarising research and design decisions to
supervisor.
\\ \hline
03/11/16 - 16/11/16 Michaelmas Weeks 5-6 & \textbf{Implementation:
	Preliminaries}.
Preliminary implementation should be completed during this phase. This includes
the parser for the format determined during the research phase and an
implementation of the internal representation and associated music-theoretic
tooling. Once this has been completed, work should commence on the MVS
implementation.

\textbf{Deliverable}: Working parser with accompanying (passing) tests.
\\ \hline

17/11/16 - 30/11/16 Michaelmas Weeks 7-8 & \textbf{Implementation: MVS}.
Continue implementation of MVS. The MVS need not be complete in the exact
viewpoints used, but the underlying machinery should be.

\textbf{Deliverable}: Working (although not necessarily complete) MVS.
\\ \hline

01/12/16 - 14/12/16 Xmas Vac. Weeks 1-2 & \textbf{Implementation: RNN}.
Begin implementation of RNN.  \\ \hline
15/12/16 - 04/01/17 Xmas Vac. Weeks 3-5 & \textbf{Implementation: MVS II}.
Refine implementation of MVS. Experiment with various different viewpoints.

\\ \hline
05/01/17 - 18/01/17 Xmas Vac. Weeks 6-7 & \textbf{Implementation: RNN II}.
Refine implementation of RNN. 

\textbf{Deliverable}: Demonstration of RNN and MVS to supervisor for start of
term.
\\ \hline

19/01/17 - 01/02/17 Lent Weeks 1-2 & \textbf{Review}.
Review progress so far. Continue iteratively refining models. Design listening
trials for evaluation.

\textbf{Deliverable}: Progress Report \& Presentation \emph{due 12pm, 3rd
	February}.
\\ \hline

02/02/17 - 15/02/17 Lent Weeks 3-4 & \textbf{Evaluation}.
Arrange and conduct listening trials. Also perform any ``offline'' evaluation in
this phase e.g. collecting data from models, analysing output etc.
\\ \hline

16/02/17 - 01/03/17 Lent Weeks 5-6 & \textbf{Dissertation: Preparation}.
Finish evaluation and data collection. Start to write Evaluation and Conclusion
chapters of dissertation.
\\ \hline

02/03/17 - 15/03/17 Lent Weeks 7-8 & \textbf{Dissertation: Introduction}.
Start writing introduction for dissertation. Sketch outline of inner chapters
(even if only in bullet-point form).

\textbf{Deliverable}: First draft of dissertation outline to supervisor.
\\ \hline

16/03/17 - 29/03/17 Easter Vac. Weeks 1-2 & \textbf{Dissertation}.
Continue writing dissertation. 

\textbf{Deliverable}: draft to supervisor.
\\ \hline

30/03/17 - 12/04/17 Easter Vac. Weeks 3-4 & 
Applying supervisor's corrections to dissertation. Continue working on
dissertation (e.g. figures etc.)
\\ \hline

13/04/17 - 26/04/17 Easter Vac. Weeks 5-6 & 
Aim to finish the dissertation by the end of the Easter vacation.
\\ \hline
%27/04/17 - 10/05/17 Easter Weeks 1-2
%11/05/17 - 17/05/17 Easter Week 3
\end{longtable}

\printbibliography

\end{document}
