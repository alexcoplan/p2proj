% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[UKenglish]{isodate}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{parskip}
\usepackage{verbatim}
\usepackage{color}
\usepackage{enumitem}
\usepackage{longtable}
\usepackage{microtype}
\usepackage{stmaryrd}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{lilyglyphs}
\usepackage{fontspec}
\usepackage{csquotes}
\usepackage{float} % figure positioning

\newcommand{\set}[1]{ \left\{ #1 \right\} }
\newcommand{\insharp}[0]{\sharp[raise=0.1,scale=0.8]}
\newcommand{\inflat}[0]{\flat[raise=0.1,scale=0.8]}

\usepackage[style=numeric,backend=biber]{biblatex}
\addbibresource{refs.bib}

\usepackage{docmute}   % only needed to allow inclusion of proposal.tex

\newcommand{\todo}{\textcolor{red}{\textbf{todo}~}}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\cleanlookdateon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title

\pagestyle{empty}

\rightline{\LARGE \textbf{Alex Coplan}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{A Comparison of Statistical Models and Recurrent Neural Networks for the
Generation of Music} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
St Catharine's College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{r p{10.5cm}}
Name:               & \bf Alex Coplan                       \\
College:            & \bf St Catharine's College                     \\
Project Title:      & \bf A Comparison of Statistical Models and Recurrent
Neural Networks for the \newline Generation of Music \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2017  \\
Word Count:         & \todo\footnote{1} \\
Project Originator: & Alex Coplan \\
Supervisor:         & Matthew Ireland                    \\ 
\end{tabular}
}
\footnotetext[1]{This word count was computed
by \texttt{detex diss.tex | tr -cd '0-9A-Za-z $\tt\backslash$n' | wc -w}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

The original aim of this project was to implement two models for music
generation and subsequently compare them: namely, a \emph{recurrent neural
network} and \emph{multiple viewpoint system}. The two models were
to be compared using both a listening survey involving human participants and
objective metrics of evaluation, such as information-theoretic measures
of predictive performance.

\section*{Work Completed}

All that has been completed appears in this dissertation.

\section*{Special Difficulties}

\todo
 
\newpage
\section*{Declaration}

I, Alex Coplan of St Catharine's College, being a candidate for Part II of the
Computer Science Tripos, hereby declare that this dissertation and the work
described in it are my own work, unaided except as may be specified below, and
that the dissertation does not contain material that has already been used to
any substantial extent for a comparable purpose.

\bigskip
\leftline{Signed }

\medskip
\leftline{Date }

\tableofcontents

\listoffigures

\newpage
\section*{Acknowledgements}

Acknowledge acknowledge acknowledge.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

The modelling and automated generation of music is a central task in an approach
to understanding computational creativity. It is natural to ask whether
computers can produce music that is compelling to humans, and indeed, this
question has long been posed by researchers, with practical efforts dating back
to the mid-1950s \cite{ames1987automated}. 

This dissertation investigates the application of two modern techniques to
\emph{melody generation}, a task highly amenable to statistical
modelling and machine learning. 

An automated system for melody generation is motivated by end-user applications
in \emph{computer-assisted composition}, whereby the system can provide
inspiration for a human composer, either by generating entirely novel melodies
within stylistic constraints, or extemporising on or extending melodic
fragments written by the human composer. Such a system might augment the
capabilities of typical music notation software. 

Markov modelling is a simple yet effective technique for capturing the
statistics of sequential data. An obvious tool to apply to the modelling of
melody is the Markov chain \cite{ames1989markov}. However, an important
observation to make is that music has a rich underlying structure: modelling the
statistics of notes directly (the \emph{surface structure}) is insufficient to
capture the complex language of musical style. This observation motivated the
development of more sophisticated models, known as \emph{multiple viewpoint
systems} \cite{conklin1995viewpoints}.  A multiple viewpoint system exploits the
rich underlying event structure of complex languages by combining the
predictions of an ensemble of context models, each modelling a different
attribute of an event space.

Recurrent neural networks (RNNs), the natural topology of neural network for
modelling sequential data, have been widely applied to tasks such as language
modelling, image captioning, time-series modelling and forecasting,
and indeed to the modelling of music (\todo cite). A RNN is an end-to-end
sequence learning tool which relies on very little domain knowledge aside from
the chosen input representation. This means that a system designed for
character-level language modelling can equally be trained to model melody
without changing the network architecture. In practice, however, we shall see
that slight architectural modifications can be of use.

The aim of this work is to compare the performance of multiple viewpoint systems
with that of recurrent neural networks on a task of stylistically-constrained
melody generation. In particular, we assess the predictive performance of the
models on a corpus of melodies used in the chorale harmonisations of J.S.\ Bach.
Furthermore, we compare the sampled outputs from each model by means of a
listening survey involving human participants.

\section{Background}

\subsection{Music Theory}

The development and implementation of the recurrent neural network in this work
can be understood with minimal knowledge of music theory. In general, the
multiple viewpoint formalism can also be expressed independently of any domain
knowledge.  However, to understand the application of the multiple viewpoint
framework to music requires an elementary understanding of music theory.  This
section introduces the relevant terminology to enable such discussion.

We shall constrain our discussion to the context of Western classical music,
since the style which we wish to model lies within this context. A \emph{pitch}
is an abstract concept which is related to the frequency of a musical note.
Formally, if $p,q$ are pitches with corresponding frequencies $\nu_p,\nu_q$,
then if $\nu_q = 2\nu_p$, $p$ and $q$ are said to span an \emph{octave}, with
$q$ an octave above $p$. In Western classical music, each octave is divided into
twelve distinct \emph{note names} (A through G modified by accidentals
\insharp{} or \inflat{}). A note name, such as `B\inflat' (or, equivalently,
A\insharp), is typically thought of as not just a single pitch, but a
\emph{pitch class}, the set of all pitches an integer number of octaves above or
below any pitch with that note name.  Formally, given some reference frequency
$\nu_n$ for a note name $n$, the set of frequencies of the pitches in the pitch
class for $n$ is given by $\set{ 2^k \cdot \nu_n\ |\ k \in \mathbb{Z} }.$

The mapping between pitch and frequency is known as \emph{temperament}, which on
modern instruments is typically \emph{equal}, meaning that the frequency space is
equally divided among the twelve pitches in an octave. More precisely, the
$(k+1)$\textsuperscript{th} note of the chromatic scale with base frequency $\nu_0$ is
given by $2^{k/12}\cdot\nu_0$. As an aside, all recordings of
model outputs in this work were made using equal temperament. Herein
we will work with the abstraction of pitch, ignoring the underlying frequencies
of notes.

To refer to specific pitches, we make use of \emph{scientific pitch notation}
(SPN). Write $N_k$ where $N$ is a note name and $k$ is an octave number. To
ground all the definitions made thus far, we use the standard reference
frequency $\mathrm{A}_4 \triangleq 440\ \mathrm{Hz}$. An \emph{interval} refers
to the difference in pitch between two notes. Consecutive note names are said to
be a \emph{semi-tone} apart, and an interval of two semi-tones is known as a
\emph{tone}. Later in this work we shall further abstract pitch and intervals
using MIDI pitch numbering, and further concepts shall be defined as necessary.
In the MIDI tuning standard, $\mathrm{A}_4$ corresponds to pitch number $69$.

\todo talk about key/tonality? this section getting quite long \ldots

\subsection{Melody Generation}

\todo Reference literature to explain why this is difficult task.

\section{Work Accomplished}

A complete framework for implementing Multiple Viewpoint Systems in \verb!C++!
has been implemented. The formalism as described by Conklin et al.\
\cite{conklin1995viewpoints} has been fully implemented.  At a low level, the
\emph{prediction by partial match} (PPM) algorithm \cite{cleary1984ppm} was
implemented for smoothing variable-order context models, which can be
parameterised over arbitrary types using \verb!C++!  templates. The distributions
predicted by these context models can be combined using either a \emph{weighted
arithmetic} scheme (as per \cite{conklin1995viewpoints}) or \emph{weighted
geometric} scheme, the latter found to be more effective by both Pearce
\cite{pearce2005construction} and Whorley \cite{whorley2013phd}.

Abstractions were made such that, using these primitives, \emph{primitive},
\emph{derived}, \emph{linked}, and \emph{triply-linked} viewpoints can be
instantiated over arbitrary combinations of types. Both a \emph{long-term}
model, for capturing regularity throughout the corpus, and a \emph{short-term}
model, for capturing the regularity within a composition, were implemented.
Sampling by random walk was implemented for melody generation.  Finally, an
automatic viewpoint selection algorithm in the form of \emph{forward step-wise
selection} \cite{whorley2013phd} was implemented.

Code for corpus preparation and analysis was written in Python using the
\texttt{music21} package. This code was used by both the MVS and RNN
implementations.

A multi-layer LSTM recurrent neural network was implemented in Python using
TensorFlow \cite{abadi2016tensorflow}. The network includes \emph{dropout} for
regularisation as per Zaremba et al.\ \cite{zaremba2014recurrent}. A decoupled
``front-end'' to the RNN was implemented which allows the same internal model to
be used for character-level language modelling and music modelling. Random walk
sampling was implemented for generation. In addition, modifications to the
conventional sequence-prediction RNN architecture were made by feeding the
network additional \emph{global} musical information at each timestep, which was
found to improve performance significantly.

Finally, a website for human evaluation was developed. This will be discussed in
detail in Chapter~\ref{chap:eval}.

\section{Related Work}

The general method of multiple viewpoints was first applied to music in 1986 by
Ebcioğlu in a rule-based system for chorale harmonisation
\cite{ebcioglu1986expert}.  This system used hand-crafted rules written in
first-order logic which were expressed in terms of different viewpoints of the
music. This system did not make use of Markov models, the main primitive
underlying \emph{statistical} viewpoint systems.

In 1988, Conklin and Cleary \cite{conklin1988modelling} applied multiple
viewpoints with underlying probabilistic Markov models to modelling Gregorian
chant and simple two-part polyphony. The authors make use of the
\emph{prediction by partial match} (PPM) algorithm \cite{cleary1984ppm} for
smoothing variable-order Markov models, but the escape method used is not
specified.  An ad-hoc, unweighted method is used for combining the predictions
of viewpoints.

Conklin and Witten went on to develop a formalism around multiple viewpoints in
a key 1995 paper \cite{conklin1995viewpoints}. The authors justify discounting
the
\emph{knowledge engineering} approach:

\begin{displayquote}
``There are too many exceptions to any
logical system of musical description, and it will be difficult to ensure the
completeness of an intuited theory. The system will always exclude some valid
pieces. The generations of a theory are bound to reflect the biases of an
engineer; this is the only way they might be called creative.''
\end{displayquote}

With similar reasoning, we shall only consider models which learn from data.  At
this point in time, the convention in the literature became to use ``multiple
viewpoint system'' to refer to \emph{statistical} viewpoint systems with
underlying context models: a convention we shall also adopt.

Many of the ideas in this paper were first published in Conklin's 1990 thesis
\cite{conklin1990prediction}. The notion of separate \emph{long-term} and
\emph{short-term} models in a viewpoint system was introduced in this work.
Conklin also details a principled method for distribution combination, namely
\emph{entropy-weighted arithmetic combination}. 

Among the contributions from his 2005 thesis \cite{pearce2005construction},
Pearce introduces a \emph{geometric} viewpoint combination technique, shown to
outperform its arithmetic counterpart, as well as a method for automatic
viewpoint selection, thereby greatly reducing the selection bias in multiple
viewpoint systems. The work concerns the modelling of melody.

More recent work by Whorley~\cite{whorley2013phd} uses multiple viewpoint
systems to model four-part harmony in Bach chorales.


\section{Structure}

\todo

\chapter{Preparation}

A high-level goal of this work which motivates the choice of models involved is
understanding to what extent \emph{feature engineering} impacts the
effectiveness of musical models. A recurrent neural network, at one extreme, is
a domain-independent, end-to-end learning system, capable of learning to extract
high-level features from sequential data (\todo cite?). A system of viewpoints,
however, relies on its creator to use domain knowledge to determine a set of
salient features, encoded in the form of the \emph{pool} of viewpoints made
available to the system.

\todo mention \textbf{starting point}: not sure where this should go right now.

\section{Deliverables}

Recalling the proposal, the success criteria for the project include the
following deliverables:
\begin{itemize}
  \item A program or tool for importing the corpus in the desired format.
  \item A multiple viewpoint system (MVS) capable of generating melody.
  \item A recurrent neural network (RNN) capable of generating melody.
  \item Quantitative and human evaluation.
\end{itemize}

This chapter concerns the ideas behind the first three of these, along with
a discussion of the research and decisions made prior to implementation.
Chapter~\ref{chap:eval} will discuss the design and implementation of the
human evaluation survey in detail, as well as quantitative evaluation.

\section{Corpus Preparation}

The chosen corpus was a set of chorale melodies used in the harmonisations of
J.S.\ Bach. The Bach Chorales are a corpus of great interest in the
computational modelling of music: the style is unified, yet with significant
inter-opus variance; it is not too complex, yet not overly simplistic.

Initial inspection of relevant corpora and their formats indicated that writing
a parser for an established music notation format such as MusicXML would take a
considerable amount of time and offer limited flexibility. After further
research, it was decided that the Python package \texttt{music21} would be
utilised. \texttt{music21} is an open-source toolkit for computational
musicology. This package was especially useful for the task of corpus
preparation due to the following features:
\begin{itemize}
  \item Built-in corpora including the Bach chorales in MusicXML format.
  \item Parser for various music notation formats, including MusicXML.
  \item High-level features for manipulating musical data.
\end{itemize}

As will be discussed later, the flexibility offered by \texttt{music21} became
of great use later in the project as the requirements in corpus preparation and
analysis changed.

An internal format for melody based on a representation used commonly in the
multiple viewpoint system literature (e.g.\ \cite{conklin1995viewpoints}) was
decided on. It was decided that musical time should be quantised with a quantum
of $1/16$\textsuperscript{th} notes (semiquavers). 

This representation was to be used internally for both the MVS and
RNN implementations. A note $n$ is represented as a tuple $(p,o,d) \in
\mathbb{N}^3$ where $p$ is the MIDI pitch number of $n$, $o$ is the onset 
time, and $d$ is the duration. A melody is then a list of such tuples. Note that
rests are not explicitly represented in this encoding.

\section{Multiple Viewpoint Systems}

In this section, the key theory, algorithms, and data structures underpinning
multiple viewpoint systems are introduced. The notation and formalism is as per
Conklin and Witten \cite{conklin1995viewpoints}. We start by defining some
notation which will be used throughout this section.

\begin{itemize}[itemsep=0mm]
  \item If $\tau$ is a type, then $[\tau]$ is the \emph{syntactic domain} of
    that type: all elements of type $\tau$.   
  \item $S^*$ denotes the set of all sequences drawn from a set $S$.
  \item $e_i^j$ abbreviates the sequence $(e_i,e_{i+1},\ldots,e_{j-1},e_j)$ and
    $()$ the empty sequence.
  \item $s :: e$ denotes the sequence $s$ with event $e$ appended.
  \item $\zeta$ denotes the \emph{event space}, the set of all possible events
    that can occur in sequences of interest. For example, a simple event space
    for melody might be:
    $$ [\mathrm{pitch}] \times [\mathrm{duration}] \times [\mathrm{rest}]. $$
\end{itemize}

\subsection{Context Models}

The central primitive underlying a multiple viewpoint system is the
\emph{context model}. In general, a context model modelling some type $\tau$ is
a data structure storing sequences in $[\tau]^*$, together with an inference
procedure predicting distributions over $[\tau]$.

While first-order Markov chains make predictions based on just one timestep of
context, an $n$\textsuperscript{th} order Markov chain makes predictions based
on $n$ elements of context. For notational convenience, and for consistency with
the literature, we generally refer to the \emph{history} $h = n+1$ of an
$n$\textsuperscript{th} order Markov model. Such a model stores and models
$h$-grams.

The context models we consider are variable-order Markov models with some
maximum history $\hbar$.  Such a model can be thought of as a combination of
Markov models with history $1,2,\ldots,\hbar$. 

A known problem with high-order Markov models is their space complexity. A naïve
tabular approach uses $\Theta(|[\tau]|^h)$ space.  In practice, such high-order
models are \emph{sparse}: most $h$-grams are never seen in the training data. A
data structure which exploits this sparsity is the \emph{suffix tree} or
\emph{trie}.  In such a structure, the nodes are events, each with an associated
count, and a path from the root corresponds uniquely to a particular $h$-gram.
Figure~\ref{fig:dur-trie} illustrates this data structure, in this case the trie
supporting a context model over musical durations. 

\begin{figure}[H]
\centering
\includegraphics[width=455pt]{figs/duration_vp.pdf}
\caption{Trie for a context model over duration with $\hbar = 3$}
\label{fig:dur-trie}
\end{figure}

The algorithm for extracting $h$-grams for a training sequence $e_1^k$ works by
passing a sliding window of size $\hbar$ across the input sequence, and
generating the sequences $e_{i-\hbar+1}^{i}, e_{i-\hbar+2}^{i}, \ldots,\ e_i^i,
()$ for $i \in [\hbar,k]$. For $i \in [1,\hbar-1]$, a smaller window size is
used to avoid running off the left end of our input sequence. \todo [give full
pseudocode in the appendix or implementation chapter and reference here? or
pseudocode here? it's only six lines]. This sliding window procedure is
illustrated in Figure~\ref{fig:hgram-extract} for an input sequence $e_1^5$.

\begin{figure}[H]
\centering
\includegraphics[width=300pt]{figs/sliding_window_tmp.jpg}
\caption{Illustration of the $h$-gram extraction algorithm with $\hbar = 3$}
\label{fig:hgram-extract}
\end{figure}

Each $h$-gram $e_i^j$ generated by the extraction algorithm is passed to a
subroutine which looks up $e_i^j$ in the trie. If it is found, then its count is
incremented. Otherwise, $e_i^j$ is inserted into the trie, the resulting node
initialised to have a count of 1. Note that $()$, the empty sequence,
corresponds to the root node in the trie.

Once we have constructed the trie for a context model, we need an algorithm to
perform \emph{inference}. In particular, we want to compute $\mathbb{P}(e' |
e_1^k)$ for some next event $e' \in [\tau]$ and input context $e_1^k \in
[\tau]^*$.

The maximum likelihood solution to this problem is simply to use the relative
frequency of the $h$-gram of interest:
\begin{equation}
  \mathbb{P}(e'|e_1^k) = \frac{ C(e_1^k::e') }{ \sum_{e''} C(e_1^k::e'') }
  \label{eq:ctx-max-like}
\end{equation}
where $C(e_i^j)$ denotes the count associated with $e_i^j$ in the trie, or $0$
if such a node does not exist. Note that all sequences longer than $\hbar$ (and
contexts longer than $\hbar-1$) are implicitly ignored, so $\forall j \in
\mathbb{N}.\ C(e_{k-\hbar-j}^k) = C(e_{k-\hbar+1}^k)$ and
$\mathbb{P}(e'|e_{k-\hbar+1-j}^k) = \mathbb{P}(e'|e_{k-\hbar+2}^k)$.

There are two main problems with this solution. The first is that we want our
models to be \emph{non-exclusive}; that is, $\forall e' \in [\tau].\
\mathbb{P}(e' | e_1^k) > 0$. An \emph{exclusive} model would limit the scope for
creativity in the system, and moreover, from a practical standpoint, evaluation
metrics such as \emph{cross-entropy} require calculating log-probabilities: we
therefore want to avoid zero probabilities. This model, however, may be
exclusive.

The second problem with this solution is that it does not deal with \emph{novel
contexts}. In particular, suppose we have not seen the context $e_1^k$. Then,
clearly, the denominator of (\ref{eq:ctx-max-like}) will be zero, which is
equally problematic.

An algorithm which attends to both of these issues is \emph{prediction by
partial match} (PPM) \cite{cleary1984ppm}. The central idea behind PPM is that,
instead of distributing the probability mass entirely among the complete
matches, as per (\ref{eq:ctx-max-like}), we instead reserve some amount of the
probability mass known as the \emph{escape probability}. The escape probability
is then distributed recursively among a lower-order model. In this sense, PPM
implements \emph{backoff smoothing}.

\todo PPM A Pseudocode

\subsection{Viewpoints}

\todo formalism

\subsection{Combining Viewpoints}

\todo MVS architecture diagram

\section{Recurrent Neural Networks}

\subsection{Basic RNN}

\todo RNN explanation with diagram as per Goodfellow DL book.

\subsection{LSTM}

\todo Explain exploding/vanishing gradients.

\todo LSTM explanation, citing papers on constant gradient flow.

\subsection{Regularisation}

\todo Explain dropout applied to RNN.

\subsection{Tooling}

\todo Explain TensorFlow, \textbf{why it was chosen}, notion of computational
graph, etc.

\chapter{Implementation}

\section{Corpus Preparation and Analysis}

\todo Maybe some graphs illustrating distributions in corpus as per
\texttt{analyse\_corpus.py}.

\section{Multiple Viewpoint System}

\todo Using the framework of multiple viewpoints outlined in the preparation,
discuss the \emph{specific} viewpoints implemented.

\subsection{Software Architecture}

\todo Diagram illustrating the (code) architecture of the MVS. 

\todo Explain use of
\texttt{C++} templates illustrating correspondence between formalism and
implementation.

\section{Recurrent Neural Network}

\subsection{Early Experiments}

\todo Mention language modelling precursor: maybe include snippet of output?

\subsection{Corpus Preprocessing}

\todo Describe the method of \emph{tonal inflation} in order for the RNN to
learn the key as an emergent property of each composition.

\subsection{Domain-specific Features}

\todo Explain ``clock'' inputs. Discuss symmetry with multiple viewpoints.

\chapter{Evaluation}\label{chap:eval}


\chapter{Conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\todo
\printbibliography

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Project Proposal}

\todo uncomment me!
%\input{proposal}

\end{document}
