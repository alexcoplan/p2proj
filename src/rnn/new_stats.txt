# HP1 Dataset

base params:
 - seq_length: 200
 - learning_rate (initial): 1.0
 - max_grad_norm: 5

## one layer
 - h64,  e50, lrd0.95 => loss: (2.135 train, 2.180 test)
 - h64,  e50, lrd0.98 => loss: (1.945 train, 2.051 test)
 - h128, e50, lrd0.98 => loss: (1.534 train, 1.671 test)

## two layers
 - h64,  e100, lrd0.98 => loss: (1.840 train, 1.901 test)
 - h128, e100, lrd0.98 => loss: (1.608 train, 1.712 test)

# Chorale (inflated: +/-3) dataset

base params:
 - seq_length: 80
 - learning_rate (initial): 1.0
 - max_grad_norm: 5

## one layer
 - h128, seqlen40, e100, lrd0.98 => loss(2.162 train, 2.410 test)
   - further 40 epochs => loss(1.837 train, 2.403 test)
   - further 40 epochs => loss(1.596 train, 2.512 test)
 - h512, seqlen40, e40, lrd0.98 => loss(1.595 train, 2.551 test)

## two layers
 - h256, seqlen80, e100, lrd0.98 => loss(2.131 train, 2.672 test)
 - h256, seqlen40, e100, lrd0.98 => loss(1.157 train, 3.024 test)
 - h256, seqlen40, e80,  lrd0.98, drop0.8 => loss(1.921 train, 2.456 test)
 - h256, seqlen40, e100, lrd0.98, drop0.5 => loss(2.205 train, 2.421 test)
  - further 9  epochs => loss(2.197 train, 2.367 test)
  - further 11 epochs => loss(2.075 train, 2.348 test)
 - h512, seqlen40, e100, lrd0.98, drop0.5 => loss(1.832 train, 2.549 test)
* provisional: test readings on nets with dropout may be incorrect

# Chorale (inflated +/-3) dataset with time sig clock (1)

based on sampling from these nets, I determined that the clock encoding
might not be optimal. instead, perhaps we should give the bar position in
semiquavers?

better sampling algorithms would obviously help as well

base:
 - seqlen40

## one layer

 - h256, e60, lrd0.95 => loss(1.913 train, 2.391 test)

## two layers

 - h512, e100, keep0.5, lrd0.98 => loss(1.810 train, 2.413 test)

# Chorale infl3 with clock mode (3): semiquaver-level clock

## one layer

 - h256, e60, lrd0.95 => loss(1.957 train, 2.402 test)
 - h320, e60, lrd0.95 => loss(1.924 train, 2.413 test)
